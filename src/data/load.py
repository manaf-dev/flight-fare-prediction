"""
Responsible for reading the raw CSV and returning a DataFrame with normalised column names.

Design decisions:
- Column normalisation (snake_case, remove special chars) happens here so that all downstream modules receive consistent column names.
- Datetime parsing happens here because it is a pure I/O concern.
- No business logic or feature engineering lives here.
"""

import re

import pandas as pd

from src.config import DATETIME_COLS, RAW_DATA_PATH
from src.utils import get_logger

logger = get_logger(__name__)


def _to_snake_case(text: str) -> str:
    """Convert a column header to lowercase snake_case."""
    text = text.strip().lower()
    text = text.replace("&", "and")
    text = re.sub(r"[^a-z0-9]+", "_", text)  # replace non-alphanumeric with _
    text = re.sub(r"_+", "_", text)  # collapse multiple underscores
    return text.strip("_")


def load_raw(path=RAW_DATA_PATH) -> pd.DataFrame:
    """
    Load the flight price CSV and return a DataFrame with clean column names.

    Steps:
    1. Read CSV.
    2. Drop accidental Pandas index columns (``Unnamed: 0`` etc.).
    3. Normalise all column headers to snake_case.
    4. Parse known datetime columns.

    Args:
        path: Path to the CSV file. Defaults to the path in ``config.py``.

    Returns:
        Raw DataFrame ready for preprocessing.

    Raises:
        FileNotFoundError: If the CSV does not exist at ``path``.
    """
    path = str(path)
    logger.info("Loading dataset from: %s", path)

    df = pd.read_csv(path)

    # Drop accidental index columns generated by pandas.
    unnamed = [c for c in df.columns if c.strip().lower().startswith("unnamed")]
    if unnamed:
        logger.info("Dropping unnamed index columns: %s", unnamed)
        df = df.drop(columns=unnamed)

    # Normalise column names.
    df.columns = [_to_snake_case(c) for c in df.columns]

    # Parse datetime columns — alias both common naming conventions.
    datetime_aliases = {
        "departure_date_and_time": "departure_datetime",
        "arrival_date_and_time": "arrival_datetime",
    }
    df = df.rename(
        columns={k: v for k, v in datetime_aliases.items() if k in df.columns}
    )

    for col in DATETIME_COLS:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], errors="coerce")

    logger.info(
        "Dataset loaded — shape: %s | datetime nulls: departure=%s, arrival=%s",
        df.shape,
        df["departure_datetime"].isna().sum()
        if "departure_datetime" in df.columns
        else "N/A",
        df["arrival_datetime"].isna().sum()
        if "arrival_datetime" in df.columns
        else "N/A",
    )
    return df
